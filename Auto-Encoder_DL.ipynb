{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a1019b6",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-05-18T20:46:50.905702Z",
     "iopub.status.busy": "2023-05-18T20:46:50.905218Z",
     "iopub.status.idle": "2023-05-18T20:46:50.917081Z",
     "shell.execute_reply": "2023-05-18T20:46:50.915969Z"
    },
    "papermill": {
     "duration": 0.024241,
     "end_time": "2023-05-18T20:46:50.919305",
     "exception": false,
     "start_time": "2023-05-18T20:46:50.895064",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Setup Chunk\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "\n",
    "import warnings \n",
    "warnings.simplefilter(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2992c97",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-18T20:46:50.935751Z",
     "iopub.status.busy": "2023-05-18T20:46:50.935438Z",
     "iopub.status.idle": "2023-05-18T20:47:00.009670Z",
     "shell.execute_reply": "2023-05-18T20:47:00.008222Z"
    },
    "papermill": {
     "duration": 9.084947,
     "end_time": "2023-05-18T20:47:00.011950",
     "exception": false,
     "start_time": "2023-05-18T20:46:50.927003",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## DL packages\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa9c7c18",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-18T20:47:00.029563Z",
     "iopub.status.busy": "2023-05-18T20:47:00.028891Z",
     "iopub.status.idle": "2023-05-18T20:47:01.300695Z",
     "shell.execute_reply": "2023-05-18T20:47:01.299572Z"
    },
    "papermill": {
     "duration": 1.28296,
     "end_time": "2023-05-18T20:47:01.302830",
     "exception": false,
     "start_time": "2023-05-18T20:47:00.019870",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Data Read\n",
    "train_clinical = pd.read_csv(\"/kaggle/input/amp-parkinsons-disease-progression-prediction/train_clinical_data.csv\")\n",
    "train_protein = pd.read_csv(\"/kaggle/input/amp-parkinsons-disease-progression-prediction/train_proteins.csv\")\n",
    "train_peptide = pd.read_csv(\"/kaggle/input/amp-parkinsons-disease-progression-prediction/train_peptides.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b9ac6c4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-18T20:47:01.320831Z",
     "iopub.status.busy": "2023-05-18T20:47:01.319471Z",
     "iopub.status.idle": "2023-05-18T20:47:01.327845Z",
     "shell.execute_reply": "2023-05-18T20:47:01.326749Z"
    },
    "papermill": {
     "duration": 0.019025,
     "end_time": "2023-05-18T20:47:01.329744",
     "exception": false,
     "start_time": "2023-05-18T20:47:01.310719",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2615, 8)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_clinical.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ba90d6",
   "metadata": {
    "papermill": {
     "duration": 0.007457,
     "end_time": "2023-05-18T20:47:01.345255",
     "exception": false,
     "start_time": "2023-05-18T20:47:01.337798",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d4028fd",
   "metadata": {
    "papermill": {
     "duration": 0.007364,
     "end_time": "2023-05-18T20:47:01.360321",
     "exception": false,
     "start_time": "2023-05-18T20:47:01.352957",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Repsonse Formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9f155a7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-18T20:47:01.377897Z",
     "iopub.status.busy": "2023-05-18T20:47:01.377529Z",
     "iopub.status.idle": "2023-05-18T20:47:21.981463Z",
     "shell.execute_reply": "2023-05-18T20:47:21.980560Z"
    },
    "papermill": {
     "duration": 20.615079,
     "end_time": "2023-05-18T20:47:21.983709",
     "exception": false,
     "start_time": "2023-05-18T20:47:01.368630",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create Targets\n",
    "\n",
    "patients = {}\n",
    "for e in range(1,5):\n",
    "    for m in [0,6,12,24]:\n",
    "        train_clinical[f'updrs_{e}_plus_{m}_months'] = 0\n",
    "\n",
    "for patient in train_clinical.patient_id.unique():\n",
    "    temp = train_clinical[train_clinical.patient_id == patient]\n",
    "    month_list = []\n",
    "    month_windows = [0,6,12,24]\n",
    "    for month in temp.visit_month.values:\n",
    "        month_list.append([month, month + 6, month + 12, month + 24])\n",
    "    for month in range(len(month_list)):\n",
    "        for x in range(1,5):\n",
    "            arr = temp[temp.visit_month.isin(month_list[month])][f'updrs_{x}'].fillna(0).to_list()\n",
    "            if len(arr) == 4:\n",
    "                for e, i in enumerate(arr):\n",
    "                    m = month_list[month][0]\n",
    "                    temp.loc[temp.visit_month == m,[f'updrs_{x}_plus_{month_windows[e]}_months']] = i\n",
    "            else:\n",
    "                temp = temp[~temp.visit_month.isin(month_list[month])]\n",
    "    patients[patient] = temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e89f675b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-18T20:47:22.001166Z",
     "iopub.status.busy": "2023-05-18T20:47:22.000820Z",
     "iopub.status.idle": "2023-05-18T20:47:22.069524Z",
     "shell.execute_reply": "2023-05-18T20:47:22.068776Z"
    },
    "papermill": {
     "duration": 0.079307,
     "end_time": "2023-05-18T20:47:22.071191",
     "exception": false,
     "start_time": "2023-05-18T20:47:21.991884",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>updrs_1_plus_0_months</th>\n",
       "      <th>updrs_1_plus_6_months</th>\n",
       "      <th>updrs_1_plus_12_months</th>\n",
       "      <th>updrs_1_plus_24_months</th>\n",
       "      <th>updrs_2_plus_0_months</th>\n",
       "      <th>updrs_2_plus_6_months</th>\n",
       "      <th>updrs_2_plus_12_months</th>\n",
       "      <th>updrs_2_plus_24_months</th>\n",
       "      <th>updrs_3_plus_0_months</th>\n",
       "      <th>updrs_3_plus_6_months</th>\n",
       "      <th>updrs_3_plus_12_months</th>\n",
       "      <th>updrs_3_plus_24_months</th>\n",
       "      <th>updrs_4_plus_0_months</th>\n",
       "      <th>updrs_4_plus_6_months</th>\n",
       "      <th>updrs_4_plus_12_months</th>\n",
       "      <th>updrs_4_plus_24_months</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>visit_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>55_0</th>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>15</td>\n",
       "      <td>34</td>\n",
       "      <td>41</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55_6</th>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>34</td>\n",
       "      <td>41</td>\n",
       "      <td>38</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55_12</th>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>9</td>\n",
       "      <td>18</td>\n",
       "      <td>41</td>\n",
       "      <td>38</td>\n",
       "      <td>49</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55_18</th>\n",
       "      <td>7</td>\n",
       "      <td>16</td>\n",
       "      <td>14</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>20</td>\n",
       "      <td>38</td>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55_24</th>\n",
       "      <td>16</td>\n",
       "      <td>14</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>18</td>\n",
       "      <td>16</td>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "      <td>51</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          updrs_1_plus_0_months  updrs_1_plus_6_months  \\\n",
       "visit_id                                                 \n",
       "55_0                         10                      8   \n",
       "55_6                          8                     10   \n",
       "55_12                        10                      7   \n",
       "55_18                         7                     16   \n",
       "55_24                        16                     14   \n",
       "\n",
       "          updrs_1_plus_12_months  updrs_1_plus_24_months  \\\n",
       "visit_id                                                   \n",
       "55_0                          10                      16   \n",
       "55_6                           7                      14   \n",
       "55_12                         16                      17   \n",
       "55_18                         14                      12   \n",
       "55_24                         17                      17   \n",
       "\n",
       "          updrs_2_plus_0_months  updrs_2_plus_6_months  \\\n",
       "visit_id                                                 \n",
       "55_0                          6                     10   \n",
       "55_6                         10                     10   \n",
       "55_12                        10                     13   \n",
       "55_18                        13                      9   \n",
       "55_24                         9                     13   \n",
       "\n",
       "          updrs_2_plus_12_months  updrs_2_plus_24_months  \\\n",
       "visit_id                                                   \n",
       "55_0                          10                       9   \n",
       "55_6                          13                      13   \n",
       "55_12                          9                      18   \n",
       "55_18                         13                      20   \n",
       "55_24                         18                      16   \n",
       "\n",
       "          updrs_3_plus_0_months  updrs_3_plus_6_months  \\\n",
       "visit_id                                                 \n",
       "55_0                         15                     34   \n",
       "55_6                         34                     41   \n",
       "55_12                        41                     38   \n",
       "55_18                        38                     49   \n",
       "55_24                        49                     49   \n",
       "\n",
       "          updrs_3_plus_12_months  updrs_3_plus_24_months  \\\n",
       "visit_id                                                   \n",
       "55_0                          41                      49   \n",
       "55_6                          38                      49   \n",
       "55_12                         49                      51   \n",
       "55_18                         49                      41   \n",
       "55_24                         51                      52   \n",
       "\n",
       "          updrs_4_plus_0_months  updrs_4_plus_6_months  \\\n",
       "visit_id                                                 \n",
       "55_0                          0                      0   \n",
       "55_6                          0                      0   \n",
       "55_12                         0                      0   \n",
       "55_18                         0                      0   \n",
       "55_24                         0                      0   \n",
       "\n",
       "          updrs_4_plus_12_months  updrs_4_plus_24_months  \n",
       "visit_id                                                  \n",
       "55_0                           0                       0  \n",
       "55_6                           0                       0  \n",
       "55_12                          0                       0  \n",
       "55_18                          0                       0  \n",
       "55_24                          0                       0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formatted_response = pd.concat(patients.values(), ignore_index=True).set_index('visit_id').iloc[:,7:]\n",
    "formatted_response.head()\n",
    "#formatted_response.isna().sum() # Check NAs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c58cac",
   "metadata": {
    "papermill": {
     "duration": 0.007626,
     "end_time": "2023-05-18T20:47:22.087168",
     "exception": false,
     "start_time": "2023-05-18T20:47:22.079542",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Cleaning Recipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4b3a6e32",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-18T20:47:22.105446Z",
     "iopub.status.busy": "2023-05-18T20:47:22.104316Z",
     "iopub.status.idle": "2023-05-18T20:47:23.101026Z",
     "shell.execute_reply": "2023-05-18T20:47:23.099777Z"
    },
    "papermill": {
     "duration": 1.008272,
     "end_time": "2023-05-18T20:47:23.103593",
     "exception": false,
     "start_time": "2023-05-18T20:47:22.095321",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "# Data cleaning recipe. \n",
    "\n",
    "def recipe(clinical, protein, peptide, verbose = True, rep = True):\n",
    "    if verbose: print('Preprocessing Steps')\n",
    "    \n",
    "    # Peptitde Abundance / Protein Expression \n",
    "    pep_over_pro = pd.merge(protein, peptide, \n",
    "                        on =['visit_id', 'visit_month', 'patient_id', \n",
    "                            'UniProt']) # joins the peptide and protein dataset\n",
    "\n",
    "    # Creates feature in new column\n",
    "    pep_over_pro['pep_per_pro'] = pep_over_pro['PeptideAbundance'] / pep_over_pro['NPX']\n",
    "    \n",
    "    if verbose: print('1. Add Peptide/Protein as new feature.')\n",
    "    \n",
    "    # Pivot the data to wide format. \n",
    "    pep_over_pro = pep_over_pro.drop(['patient_id', 'visit_month'], axis = 1).pivot(\n",
    "    index = ['visit_id'], columns = ['Peptide'], values = ['pep_per_pro'])\n",
    "    \n",
    "    # Cleans erronous levels for smooth merge. \n",
    "    pep_over_pro.columns = pep_over_pro.columns.droplevel()\n",
    "    pep_over_pro.reset_index()\n",
    "\n",
    "    train = pd.merge(clinical, pep_over_pro, on = 'visit_id', \n",
    "                 how = 'left') # left join\n",
    "    \n",
    "    train = train.set_index('visit_id') # removes as feature, but in rowname for tracking\n",
    "    \n",
    "    # Drop med_status as a predictor (DOES NOT APPEAR IN TEST DATA)\n",
    "    if rep:\n",
    "        train = train.drop(['upd23b_clinical_state_on_medication'], axis = 1)\n",
    "    \n",
    "        if verbose: print('2. Dropped med_status as a predictor.')\n",
    "        \n",
    "    # Drop patient_id as a predictor \n",
    "    train = train.drop(['patient_id'], axis = 1)\n",
    "    \n",
    "    if verbose: print('3. Dropped patient_id as a predictor.')\n",
    "    \n",
    "    ## KNN Imputation ## \n",
    "    \n",
    "    # Drops the response if it training data.\n",
    "    if rep: \n",
    "        response = train[['updrs_1', 'updrs_2', 'updrs_3', 'updrs_4']]\n",
    "        train = train.drop(['updrs_1', 'updrs_2', 'updrs_3', 'updrs_4'], axis = 1)\n",
    "    \n",
    "    # Drops the categorical variables. \n",
    "    cats = train[['visit_month']]\n",
    "    train = train.drop(['visit_month'], axis = 1)\n",
    "    \n",
    "    # Standardize numeric features. \n",
    "    scalar = StandardScaler()\n",
    "    train = pd.DataFrame(scalar.fit_transform(train), columns = train.columns,\n",
    "                        index = train.index)\n",
    "    \n",
    "    if verbose: print('4. Normalized numeric predictors.')\n",
    "    \n",
    "    # Add back in cats \n",
    "    train = train.join(cats)\n",
    "    \n",
    "    # Add unseens in testings as nan (need different imputer for much missing)\n",
    "    #if not rep:\n",
    "    #    test_add = np.setdiff1d(X.columns, \n",
    "    #                           train.columns).tolist()\n",
    "    #    \n",
    "    #    temp = pd.DataFrame(np.nan, \n",
    "    #                        columns = test_add, \n",
    "    #                        index = train.index)\n",
    "    #    train = train.join(temp)\n",
    "        \n",
    "    # Apply KNN imputation \n",
    "    imputer = KNNImputer(n_neighbors = 5)\n",
    "    train = pd.DataFrame(imputer.fit_transform(train), columns = train.columns, \n",
    "                        index = train.index)\n",
    "    if rep: \n",
    "        response = pd.DataFrame(imputer.fit_transform(response), \n",
    "                                columns = response.columns, \n",
    "                                index = response.index)\n",
    "    \n",
    "    if verbose: print('5. KNN Imputation')\n",
    "    \n",
    "    # Add back in repsonse if training data. \n",
    "    if rep: \n",
    "        train = train.join(response)\n",
    "    \n",
    "    return train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "01bf252d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-18T20:47:23.122404Z",
     "iopub.status.busy": "2023-05-18T20:47:23.121833Z",
     "iopub.status.idle": "2023-05-18T20:47:45.516667Z",
     "shell.execute_reply": "2023-05-18T20:47:45.515729Z"
    },
    "papermill": {
     "duration": 22.406503,
     "end_time": "2023-05-18T20:47:45.519045",
     "exception": false,
     "start_time": "2023-05-18T20:47:23.112542",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing Steps\n",
      "1. Add Peptide/Protein as new feature.\n",
      "2. Dropped med_status as a predictor.\n",
      "3. Dropped patient_id as a predictor.\n",
      "4. Normalized numeric predictors.\n",
      "5. KNN Imputation\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AADDTWEPFASGK</th>\n",
       "      <th>AAFGQGSGPIMLDEVQC(UniMod_4)TGTEASLADC(UniMod_4)K</th>\n",
       "      <th>AAFTEC(UniMod_4)C(UniMod_4)QAADK</th>\n",
       "      <th>AANEVSSADVK</th>\n",
       "      <th>AATGEC(UniMod_4)TATVGKR</th>\n",
       "      <th>AATVGSLAGQPLQER</th>\n",
       "      <th>AAVYHHFISDGVR</th>\n",
       "      <th>ADDKETC(UniMod_4)FAEEGK</th>\n",
       "      <th>ADDKETC(UniMod_4)FAEEGKK</th>\n",
       "      <th>ADDLGKGGNEESTKTGNAGSR</th>\n",
       "      <th>...</th>\n",
       "      <th>YVNKEIQNAVNGVK</th>\n",
       "      <th>YWGVASFLQK</th>\n",
       "      <th>YYC(UniMod_4)FQGNQFLR</th>\n",
       "      <th>YYTYLIMNK</th>\n",
       "      <th>YYWGGQYTWDMAK</th>\n",
       "      <th>visit_month</th>\n",
       "      <th>updrs_1</th>\n",
       "      <th>updrs_2</th>\n",
       "      <th>updrs_3</th>\n",
       "      <th>updrs_4</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>visit_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>55_0</th>\n",
       "      <td>-0.097394</td>\n",
       "      <td>-0.611465</td>\n",
       "      <td>-0.482302</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.555718</td>\n",
       "      <td>0.388845</td>\n",
       "      <td>-0.055969</td>\n",
       "      <td>-1.188915</td>\n",
       "      <td>0.747080</td>\n",
       "      <td>0.138628</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.235448</td>\n",
       "      <td>0.130248</td>\n",
       "      <td>-0.254317</td>\n",
       "      <td>-0.447802</td>\n",
       "      <td>-0.635128</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55_3</th>\n",
       "      <td>-0.474096</td>\n",
       "      <td>-1.122953</td>\n",
       "      <td>-0.650454</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.309951</td>\n",
       "      <td>0.157413</td>\n",
       "      <td>1.547536</td>\n",
       "      <td>0.143963</td>\n",
       "      <td>-0.820133</td>\n",
       "      <td>0.551960</td>\n",
       "      <td>...</td>\n",
       "      <td>0.933085</td>\n",
       "      <td>2.673593</td>\n",
       "      <td>1.413008</td>\n",
       "      <td>0.661591</td>\n",
       "      <td>0.246301</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55_6</th>\n",
       "      <td>-0.236887</td>\n",
       "      <td>-0.887478</td>\n",
       "      <td>-0.043868</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.775712</td>\n",
       "      <td>0.125236</td>\n",
       "      <td>-0.082369</td>\n",
       "      <td>-1.187405</td>\n",
       "      <td>1.221974</td>\n",
       "      <td>0.103260</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.578775</td>\n",
       "      <td>0.200504</td>\n",
       "      <td>-0.661579</td>\n",
       "      <td>-0.292764</td>\n",
       "      <td>-0.010148</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>3.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55_9</th>\n",
       "      <td>0.249475</td>\n",
       "      <td>-1.713341</td>\n",
       "      <td>-0.572966</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.329779</td>\n",
       "      <td>-0.103017</td>\n",
       "      <td>0.411495</td>\n",
       "      <td>-0.068773</td>\n",
       "      <td>-0.922437</td>\n",
       "      <td>0.856256</td>\n",
       "      <td>...</td>\n",
       "      <td>0.533902</td>\n",
       "      <td>0.592032</td>\n",
       "      <td>1.609423</td>\n",
       "      <td>-2.001862</td>\n",
       "      <td>-0.192085</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55_12</th>\n",
       "      <td>-0.313668</td>\n",
       "      <td>-0.911808</td>\n",
       "      <td>-0.261373</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.110614</td>\n",
       "      <td>0.979999</td>\n",
       "      <td>-0.402378</td>\n",
       "      <td>-1.176289</td>\n",
       "      <td>0.379146</td>\n",
       "      <td>0.155990</td>\n",
       "      <td>...</td>\n",
       "      <td>0.226678</td>\n",
       "      <td>0.498383</td>\n",
       "      <td>-0.876679</td>\n",
       "      <td>0.069697</td>\n",
       "      <td>0.191490</td>\n",
       "      <td>12.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 973 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          AADDTWEPFASGK  AAFGQGSGPIMLDEVQC(UniMod_4)TGTEASLADC(UniMod_4)K  \\\n",
       "visit_id                                                                    \n",
       "55_0          -0.097394                                         -0.611465   \n",
       "55_3          -0.474096                                         -1.122953   \n",
       "55_6          -0.236887                                         -0.887478   \n",
       "55_9           0.249475                                         -1.713341   \n",
       "55_12         -0.313668                                         -0.911808   \n",
       "\n",
       "          AAFTEC(UniMod_4)C(UniMod_4)QAADK  AANEVSSADVK  \\\n",
       "visit_id                                                  \n",
       "55_0                             -0.482302          0.0   \n",
       "55_3                             -0.650454          0.0   \n",
       "55_6                             -0.043868          0.0   \n",
       "55_9                             -0.572966          0.0   \n",
       "55_12                            -0.261373          0.0   \n",
       "\n",
       "          AATGEC(UniMod_4)TATVGKR  AATVGSLAGQPLQER  AAVYHHFISDGVR  \\\n",
       "visit_id                                                            \n",
       "55_0                     0.555718         0.388845      -0.055969   \n",
       "55_3                    -0.309951         0.157413       1.547536   \n",
       "55_6                     1.775712         0.125236      -0.082369   \n",
       "55_9                    -0.329779        -0.103017       0.411495   \n",
       "55_12                    0.110614         0.979999      -0.402378   \n",
       "\n",
       "          ADDKETC(UniMod_4)FAEEGK  ADDKETC(UniMod_4)FAEEGKK  \\\n",
       "visit_id                                                      \n",
       "55_0                    -1.188915                  0.747080   \n",
       "55_3                     0.143963                 -0.820133   \n",
       "55_6                    -1.187405                  1.221974   \n",
       "55_9                    -0.068773                 -0.922437   \n",
       "55_12                   -1.176289                  0.379146   \n",
       "\n",
       "          ADDLGKGGNEESTKTGNAGSR  ...  YVNKEIQNAVNGVK  YWGVASFLQK  \\\n",
       "visit_id                         ...                               \n",
       "55_0                   0.138628  ...       -0.235448    0.130248   \n",
       "55_3                   0.551960  ...        0.933085    2.673593   \n",
       "55_6                   0.103260  ...       -0.578775    0.200504   \n",
       "55_9                   0.856256  ...        0.533902    0.592032   \n",
       "55_12                  0.155990  ...        0.226678    0.498383   \n",
       "\n",
       "          YYC(UniMod_4)FQGNQFLR  YYTYLIMNK  YYWGGQYTWDMAK  visit_month  \\\n",
       "visit_id                                                                 \n",
       "55_0                  -0.254317  -0.447802      -0.635128          0.0   \n",
       "55_3                   1.413008   0.661591       0.246301          3.0   \n",
       "55_6                  -0.661579  -0.292764      -0.010148          6.0   \n",
       "55_9                   1.609423  -2.001862      -0.192085          9.0   \n",
       "55_12                 -0.876679   0.069697       0.191490         12.0   \n",
       "\n",
       "          updrs_1  updrs_2  updrs_3  updrs_4  \n",
       "visit_id                                      \n",
       "55_0         10.0      6.0     15.0      2.8  \n",
       "55_3         10.0      7.0     25.0      3.0  \n",
       "55_6          8.0     10.0     34.0      3.4  \n",
       "55_9          8.0      9.0     30.0      0.0  \n",
       "55_12        10.0     10.0     41.0      0.0  \n",
       "\n",
       "[5 rows x 973 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test recipe \n",
    "train_clinical_fresh = pd.read_csv(\"/kaggle/input/amp-parkinsons-disease-progression-prediction/train_clinical_data.csv\")\n",
    "clean_test = recipe(train_clinical_fresh, train_protein, train_peptide, rep = True)\n",
    "clean_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77122d02",
   "metadata": {
    "papermill": {
     "duration": 0.008079,
     "end_time": "2023-05-18T20:47:45.535909",
     "exception": false,
     "start_time": "2023-05-18T20:47:45.527830",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f94f6412",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-18T20:47:45.554768Z",
     "iopub.status.busy": "2023-05-18T20:47:45.554004Z",
     "iopub.status.idle": "2023-05-18T20:47:45.564123Z",
     "shell.execute_reply": "2023-05-18T20:47:45.562723Z"
    },
    "papermill": {
     "duration": 0.021812,
     "end_time": "2023-05-18T20:47:45.566316",
     "exception": false,
     "start_time": "2023-05-18T20:47:45.544504",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Extract the peptide/protein data to be reduced. \n",
    "clean_pep_pro = clean_test.iloc[:, :clean_test.shape[1] - 5]\n",
    "#clean_pep_pro.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b002932f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-18T20:47:45.585172Z",
     "iopub.status.busy": "2023-05-18T20:47:45.584674Z",
     "iopub.status.idle": "2023-05-18T20:47:45.798734Z",
     "shell.execute_reply": "2023-05-18T20:47:45.797304Z"
    },
    "papermill": {
     "duration": 0.225516,
     "end_time": "2023-05-18T20:47:45.800576",
     "exception": false,
     "start_time": "2023-05-18T20:47:45.575060",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 500)               484500    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 500)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 250)               125250    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 250)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                2510      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 612,260\n",
      "Trainable params: 612,260\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Encoder Network\n",
    "input_shape = [clean_pep_pro.shape[1]]\n",
    "latent_shape = 10\n",
    "\n",
    "encoder = tf.keras.Sequential()\n",
    "encoder.add(Dense(500, input_shape = input_shape, activation = 'relu'))\n",
    "encoder.add(Dropout(0.2))\n",
    "encoder.add(Dense(250, activation = 'relu'))\n",
    "encoder.add(Dropout(0.2))\n",
    "encoder.add(Dense(latent_shape, activation = 'relu'))\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "95c5f9c5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-18T20:47:45.821475Z",
     "iopub.status.busy": "2023-05-18T20:47:45.821121Z",
     "iopub.status.idle": "2023-05-18T20:47:45.968130Z",
     "shell.execute_reply": "2023-05-18T20:47:45.966952Z"
    },
    "papermill": {
     "duration": 0.160228,
     "end_time": "2023-05-18T20:47:45.970538",
     "exception": false,
     "start_time": "2023-05-18T20:47:45.810310",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_3 (Dense)             (None, None, 50)          550       \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, None, 50)          0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, None, 250)         12750     \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, None, 250)         0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, None, 500)         125500    \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, None, 500)         0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, None, 968)         484968    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 623,768\n",
      "Trainable params: 623,768\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Decoder Network\n",
    "decoder = tf.keras.Sequential()\n",
    "decoder.add(Dense(50, input_shape = encoder.output_shape, activation = 'relu'))\n",
    "decoder.add(Dropout(0.2))\n",
    "decoder.add(Dense(250, activation = 'relu'))\n",
    "decoder.add(Dropout(0.2))\n",
    "decoder.add(Dense(500, activation = 'relu'))\n",
    "decoder.add(Dropout(0.2))\n",
    "decoder.add(Dense(input_shape[0]))\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2b6a68e2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-18T20:47:45.993050Z",
     "iopub.status.busy": "2023-05-18T20:47:45.992761Z",
     "iopub.status.idle": "2023-05-18T20:47:46.045154Z",
     "shell.execute_reply": "2023-05-18T20:47:46.043469Z"
    },
    "papermill": {
     "duration": 0.066719,
     "end_time": "2023-05-18T20:47:46.047928",
     "exception": false,
     "start_time": "2023-05-18T20:47:45.981209",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 968)]             0         \n",
      "                                                                 \n",
      " sequential (Sequential)     (None, 10)                612260    \n",
      "                                                                 \n",
      " sequential_1 (Sequential)   (None, None, 968)         623768    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,236,028\n",
      "Trainable params: 1,236,028\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Auto-encoder Network\n",
    "visit = keras.Input(shape = input_shape)\n",
    "latent_vector = encoder(visit)\n",
    "output = decoder(latent_vector)\n",
    "\n",
    "auto_encoder = keras.Model(inputs = visit, outputs = output)\n",
    "auto_encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "abd017ff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-18T20:47:46.074456Z",
     "iopub.status.busy": "2023-05-18T20:47:46.073506Z",
     "iopub.status.idle": "2023-05-18T20:49:04.188367Z",
     "shell.execute_reply": "2023-05-18T20:49:04.187744Z"
    },
    "papermill": {
     "duration": 78.130078,
     "end_time": "2023-05-18T20:49:04.190209",
     "exception": false,
     "start_time": "2023-05-18T20:47:46.060131",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "66/66 [==============================] - 2s 15ms/step - loss: 0.5257 - val_loss: 0.5089\n",
      "Epoch 2/100\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 0.4653 - val_loss: 0.4655\n",
      "Epoch 3/100\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 0.4364 - val_loss: 0.4072\n",
      "Epoch 4/100\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 0.3973 - val_loss: 0.3977\n",
      "Epoch 5/100\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 0.3828 - val_loss: 0.3796\n",
      "Epoch 6/100\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 0.3760 - val_loss: 0.3858\n",
      "Epoch 7/100\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 0.3683 - val_loss: 0.3716\n",
      "Epoch 8/100\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 0.3574 - val_loss: 0.3588\n",
      "Epoch 9/100\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 0.3524 - val_loss: 0.3532\n",
      "Epoch 10/100\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 0.3413 - val_loss: 0.3462\n",
      "Epoch 11/100\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 0.3286 - val_loss: 0.3541\n",
      "Epoch 12/100\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 0.3296 - val_loss: 0.3435\n",
      "Epoch 13/100\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 0.3246 - val_loss: 0.3427\n",
      "Epoch 14/100\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 0.3149 - val_loss: 0.3285\n",
      "Epoch 15/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.3112 - val_loss: 0.3273\n",
      "Epoch 16/100\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 0.3165 - val_loss: 0.3251\n",
      "Epoch 17/100\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 0.3059 - val_loss: 0.3225\n",
      "Epoch 18/100\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 0.3026 - val_loss: 0.3214\n",
      "Epoch 19/100\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 0.2996 - val_loss: 0.3118\n",
      "Epoch 20/100\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 0.2954 - val_loss: 0.3105\n",
      "Epoch 21/100\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 0.2900 - val_loss: 0.3087\n",
      "Epoch 22/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.2888 - val_loss: 0.3099\n",
      "Epoch 23/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.2901 - val_loss: 0.3063\n",
      "Epoch 24/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.2857 - val_loss: 0.3048\n",
      "Epoch 25/100\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 0.2801 - val_loss: 0.3087\n",
      "Epoch 26/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.2810 - val_loss: 0.3049\n",
      "Epoch 27/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.2807 - val_loss: 0.2985\n",
      "Epoch 28/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.2805 - val_loss: 0.3004\n",
      "Epoch 29/100\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 0.2793 - val_loss: 0.2972\n",
      "Epoch 30/100\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 0.2771 - val_loss: 0.3037\n",
      "Epoch 31/100\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 0.2777 - val_loss: 0.2969\n",
      "Epoch 32/100\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 0.2708 - val_loss: 0.2952\n",
      "Epoch 33/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.2740 - val_loss: 0.3029\n",
      "Epoch 34/100\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 0.2852 - val_loss: 0.2920\n",
      "Epoch 35/100\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 0.2728 - val_loss: 0.2911\n",
      "Epoch 36/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.2674 - val_loss: 0.2880\n",
      "Epoch 37/100\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 0.2654 - val_loss: 0.2929\n",
      "Epoch 38/100\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 0.2630 - val_loss: 0.2898\n",
      "Epoch 39/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.2632 - val_loss: 0.2941\n",
      "Epoch 40/100\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 0.2648 - val_loss: 0.2934\n",
      "Epoch 41/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.2637 - val_loss: 0.2925\n",
      "Epoch 42/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.2645 - val_loss: 0.2917\n",
      "Epoch 43/100\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 0.2647 - val_loss: 0.2964\n",
      "Epoch 44/100\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 0.2663 - val_loss: 0.2869\n",
      "Epoch 45/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.2642 - val_loss: 0.2937\n",
      "Epoch 46/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.2664 - val_loss: 0.2927\n",
      "Epoch 47/100\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 0.2670 - val_loss: 0.3018\n",
      "Epoch 48/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.2650 - val_loss: 0.2812\n",
      "Epoch 49/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.2647 - val_loss: 0.2837\n",
      "Epoch 50/100\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 0.2613 - val_loss: 0.2806\n",
      "Epoch 51/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.2594 - val_loss: 0.2828\n",
      "Epoch 52/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.2593 - val_loss: 0.2859\n",
      "Epoch 53/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.2645 - val_loss: 0.2944\n",
      "Epoch 54/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.2640 - val_loss: 0.2840\n",
      "Epoch 55/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.2618 - val_loss: 0.2843\n",
      "Epoch 56/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.2592 - val_loss: 0.2791\n",
      "Epoch 57/100\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 0.2556 - val_loss: 0.2813\n",
      "Epoch 58/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.2538 - val_loss: 0.2906\n",
      "Epoch 59/100\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 0.2566 - val_loss: 0.2992\n",
      "Epoch 60/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.2647 - val_loss: 0.2920\n",
      "Epoch 61/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.2563 - val_loss: 0.2922\n",
      "Epoch 62/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.2575 - val_loss: 0.2890\n",
      "Epoch 63/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.2585 - val_loss: 0.2983\n",
      "Epoch 64/100\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 0.2563 - val_loss: 0.2936\n",
      "Epoch 65/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.2512 - val_loss: 0.2905\n",
      "Epoch 66/100\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 0.2502 - val_loss: 0.2849\n",
      "Epoch 67/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.2538 - val_loss: 0.2897\n",
      "Epoch 68/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.2527 - val_loss: 0.2886\n",
      "Epoch 69/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.2517 - val_loss: 0.2883\n",
      "Epoch 70/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.2517 - val_loss: 0.2812\n",
      "Epoch 71/100\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 0.2512 - val_loss: 0.2864\n",
      "Epoch 72/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.2518 - val_loss: 0.2754\n",
      "Epoch 73/100\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 0.2470 - val_loss: 0.2808\n",
      "Epoch 74/100\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 0.2495 - val_loss: 0.2843\n",
      "Epoch 75/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.2545 - val_loss: 0.2880\n",
      "Epoch 76/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.2510 - val_loss: 0.2907\n",
      "Epoch 77/100\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 0.2538 - val_loss: 0.2864\n",
      "Epoch 78/100\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 0.2521 - val_loss: 0.2863\n",
      "Epoch 79/100\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 0.2448 - val_loss: 0.2782\n",
      "Epoch 80/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.2477 - val_loss: 0.2807\n",
      "Epoch 81/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.2454 - val_loss: 0.2812\n",
      "Epoch 82/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.2480 - val_loss: 0.2831\n",
      "Epoch 83/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.2508 - val_loss: 0.2932\n",
      "Epoch 84/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.2482 - val_loss: 0.2878\n",
      "Epoch 85/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.2451 - val_loss: 0.2833\n",
      "Epoch 86/100\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 0.2496 - val_loss: 0.2809\n",
      "Epoch 87/100\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 0.2478 - val_loss: 0.2861\n",
      "Epoch 88/100\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 0.2443 - val_loss: 0.2792\n",
      "Epoch 89/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.2424 - val_loss: 0.2805\n",
      "Epoch 90/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.2491 - val_loss: 0.2885\n",
      "Epoch 91/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.2434 - val_loss: 0.2859\n",
      "Epoch 92/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.2520 - val_loss: 0.2941\n",
      "Epoch 93/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.2488 - val_loss: 0.2861\n",
      "Epoch 94/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.2471 - val_loss: 0.2844\n",
      "Epoch 95/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.2434 - val_loss: 0.2882\n",
      "Epoch 96/100\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.2455 - val_loss: 0.2911\n",
      "Epoch 97/100\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 0.2494 - val_loss: 0.2908\n",
      "Epoch 98/100\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 0.2426 - val_loss: 0.2898\n",
      "Epoch 99/100\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 0.2403 - val_loss: 0.2896\n",
      "Epoch 100/100\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 0.2441 - val_loss: 0.2880\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7b854fbd8bb0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compile and auto-encoder model \n",
    "auto_encoder.compile('adam', loss = 'mse')\n",
    "\n",
    "auto_encoder.fit(clean_pep_pro, clean_pep_pro, epochs = 100, \n",
    "                 validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9a977759",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-18T20:49:04.380678Z",
     "iopub.status.busy": "2023-05-18T20:49:04.380109Z",
     "iopub.status.idle": "2023-05-18T20:49:04.767585Z",
     "shell.execute_reply": "2023-05-18T20:49:04.766488Z"
    },
    "papermill": {
     "duration": 0.485379,
     "end_time": "2023-05-18T20:49:04.769629",
     "exception": false,
     "start_time": "2023-05-18T20:49:04.284250",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82/82 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>visit_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>55_0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.000591</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.826263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16.530260</td>\n",
       "      <td>10.680049</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55_3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.565229</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55_6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.513136</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.417006</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>17.678373</td>\n",
       "      <td>11.336211</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55_9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.328477</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55_12</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.494810</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.715164</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.299711</td>\n",
       "      <td>10.330498</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65043_48</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.001646</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.277672</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.165310</td>\n",
       "      <td>7.309073</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65043_54</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.271467</td>\n",
       "      <td>12.787474</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65043_60</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65043_72</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.733482</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.315557</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65043_84</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.075152</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.862898</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.137490</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2615 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0    1          2    3          4    5          6          7  \\\n",
       "visit_id                                                                   \n",
       "55_0      0.0  0.0  22.000591  0.0  21.826263  0.0   0.000000  16.530260   \n",
       "55_3      0.0  0.0   0.000000  0.0   0.000000  0.0   1.565229   0.000000   \n",
       "55_6      0.0  0.0  23.513136  0.0  23.417006  0.0   0.000000  17.678373   \n",
       "55_9      0.0  0.0   0.000000  0.0   0.000000  0.0  10.328477   0.000000   \n",
       "55_12     0.0  0.0  16.494810  0.0  14.715164  0.0   0.000000  10.299711   \n",
       "...       ...  ...        ...  ...        ...  ...        ...        ...   \n",
       "65043_48  0.0  0.0  13.001646  0.0  16.277672  0.0   0.000000   9.165310   \n",
       "65043_54  0.0  0.0   0.000000  0.0   0.000000  0.0   6.271467  12.787474   \n",
       "65043_60  0.0  0.0   0.000000  0.0   0.000000  0.0   0.000000   0.000000   \n",
       "65043_72  0.0  0.0   0.000000  0.0   6.733482  0.0   0.000000   4.315557   \n",
       "65043_84  0.0  0.0   2.075152  0.0   2.862898  0.0   0.000000   1.137490   \n",
       "\n",
       "                  8    9  \n",
       "visit_id                  \n",
       "55_0      10.680049  0.0  \n",
       "55_3       0.000000  0.0  \n",
       "55_6      11.336211  0.0  \n",
       "55_9       0.000000  0.0  \n",
       "55_12     10.330498  0.0  \n",
       "...             ...  ...  \n",
       "65043_48   7.309073  0.0  \n",
       "65043_54   0.000000  0.0  \n",
       "65043_60   0.000000  0.0  \n",
       "65043_72   0.000000  0.0  \n",
       "65043_84   0.000000  0.0  \n",
       "\n",
       "[2615 rows x 10 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_encoded = encoder.predict(clean_pep_pro)\n",
    "clean_encoded = pd.DataFrame(clean_encoded, \n",
    "                             index = clean_pep_pro.index)\n",
    "clean_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d90e156b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-18T20:49:04.966586Z",
     "iopub.status.busy": "2023-05-18T20:49:04.965661Z",
     "iopub.status.idle": "2023-05-18T20:49:04.983395Z",
     "shell.execute_reply": "2023-05-18T20:49:04.982435Z"
    },
    "papermill": {
     "duration": 0.118525,
     "end_time": "2023-05-18T20:49:04.985193",
     "exception": false,
     "start_time": "2023-05-18T20:49:04.866668",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>visit_month</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>visit_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>55_0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.000591</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.826263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16.530260</td>\n",
       "      <td>10.680049</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55_3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.565229</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55_6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.513136</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.417006</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>17.678373</td>\n",
       "      <td>11.336211</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55_9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.328477</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55_12</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.494810</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.715164</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.299711</td>\n",
       "      <td>10.330498</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0    1          2    3          4    5          6          7  \\\n",
       "visit_id                                                                   \n",
       "55_0      0.0  0.0  22.000591  0.0  21.826263  0.0   0.000000  16.530260   \n",
       "55_3      0.0  0.0   0.000000  0.0   0.000000  0.0   1.565229   0.000000   \n",
       "55_6      0.0  0.0  23.513136  0.0  23.417006  0.0   0.000000  17.678373   \n",
       "55_9      0.0  0.0   0.000000  0.0   0.000000  0.0  10.328477   0.000000   \n",
       "55_12     0.0  0.0  16.494810  0.0  14.715164  0.0   0.000000  10.299711   \n",
       "\n",
       "                  8    9  visit_month  \n",
       "visit_id                               \n",
       "55_0      10.680049  0.0          0.0  \n",
       "55_3       0.000000  0.0          3.0  \n",
       "55_6      11.336211  0.0          6.0  \n",
       "55_9       0.000000  0.0          9.0  \n",
       "55_12     10.330498  0.0         12.0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features = clean_encoded.join(clean_test['visit_month'])\n",
    "train_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8094bd3f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-18T20:49:05.181601Z",
     "iopub.status.busy": "2023-05-18T20:49:05.180238Z",
     "iopub.status.idle": "2023-05-18T20:49:05.196965Z",
     "shell.execute_reply": "2023-05-18T20:49:05.195963Z"
    },
    "papermill": {
     "duration": 0.116439,
     "end_time": "2023-05-18T20:49:05.198963",
     "exception": false,
     "start_time": "2023-05-18T20:49:05.082524",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>updrs_1_plus_0_months</th>\n",
       "      <th>updrs_1_plus_6_months</th>\n",
       "      <th>updrs_1_plus_12_months</th>\n",
       "      <th>updrs_1_plus_24_months</th>\n",
       "      <th>updrs_2_plus_0_months</th>\n",
       "      <th>updrs_2_plus_6_months</th>\n",
       "      <th>updrs_2_plus_12_months</th>\n",
       "      <th>updrs_2_plus_24_months</th>\n",
       "      <th>updrs_3_plus_0_months</th>\n",
       "      <th>updrs_3_plus_6_months</th>\n",
       "      <th>updrs_3_plus_12_months</th>\n",
       "      <th>updrs_3_plus_24_months</th>\n",
       "      <th>updrs_4_plus_0_months</th>\n",
       "      <th>updrs_4_plus_6_months</th>\n",
       "      <th>updrs_4_plus_12_months</th>\n",
       "      <th>updrs_4_plus_24_months</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>visit_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>55_0</th>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>15</td>\n",
       "      <td>34</td>\n",
       "      <td>41</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55_6</th>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>34</td>\n",
       "      <td>41</td>\n",
       "      <td>38</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55_12</th>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>9</td>\n",
       "      <td>18</td>\n",
       "      <td>41</td>\n",
       "      <td>38</td>\n",
       "      <td>49</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55_18</th>\n",
       "      <td>7</td>\n",
       "      <td>16</td>\n",
       "      <td>14</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>20</td>\n",
       "      <td>38</td>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55_24</th>\n",
       "      <td>16</td>\n",
       "      <td>14</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>18</td>\n",
       "      <td>16</td>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "      <td>51</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65043_12</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65043_18</th>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65043_24</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65043_30</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65043_36</th>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>13</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>954 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          updrs_1_plus_0_months  updrs_1_plus_6_months  \\\n",
       "visit_id                                                 \n",
       "55_0                         10                      8   \n",
       "55_6                          8                     10   \n",
       "55_12                        10                      7   \n",
       "55_18                         7                     16   \n",
       "55_24                        16                     14   \n",
       "...                         ...                    ...   \n",
       "65043_12                      4                      6   \n",
       "65043_18                      6                      4   \n",
       "65043_24                      4                      3   \n",
       "65043_30                      3                      2   \n",
       "65043_36                      2                      9   \n",
       "\n",
       "          updrs_1_plus_12_months  updrs_1_plus_24_months  \\\n",
       "visit_id                                                   \n",
       "55_0                          10                      16   \n",
       "55_6                           7                      14   \n",
       "55_12                         16                      17   \n",
       "55_18                         14                      12   \n",
       "55_24                         17                      17   \n",
       "...                          ...                     ...   \n",
       "65043_12                       4                       2   \n",
       "65043_18                       3                       9   \n",
       "65043_24                       2                       7   \n",
       "65043_30                       9                       4   \n",
       "65043_36                       7                       6   \n",
       "\n",
       "          updrs_2_plus_0_months  updrs_2_plus_6_months  \\\n",
       "visit_id                                                 \n",
       "55_0                          6                     10   \n",
       "55_6                         10                     10   \n",
       "55_12                        10                     13   \n",
       "55_18                        13                      9   \n",
       "55_24                         9                     13   \n",
       "...                         ...                    ...   \n",
       "65043_12                      7                      7   \n",
       "65043_18                      7                      8   \n",
       "65043_24                      8                      4   \n",
       "65043_30                      4                      7   \n",
       "65043_36                      7                     10   \n",
       "\n",
       "          updrs_2_plus_12_months  updrs_2_plus_24_months  \\\n",
       "visit_id                                                   \n",
       "55_0                          10                       9   \n",
       "55_6                          13                      13   \n",
       "55_12                          9                      18   \n",
       "55_18                         13                      20   \n",
       "55_24                         18                      16   \n",
       "...                          ...                     ...   \n",
       "65043_12                       8                       7   \n",
       "65043_18                       4                      10   \n",
       "65043_24                       7                       6   \n",
       "65043_30                      10                       8   \n",
       "65043_36                       6                       6   \n",
       "\n",
       "          updrs_3_plus_0_months  updrs_3_plus_6_months  \\\n",
       "visit_id                                                 \n",
       "55_0                         15                     34   \n",
       "55_6                         34                     41   \n",
       "55_12                        41                     38   \n",
       "55_18                        38                     49   \n",
       "55_24                        49                     49   \n",
       "...                         ...                    ...   \n",
       "65043_12                     14                     13   \n",
       "65043_18                     13                      0   \n",
       "65043_24                      0                      4   \n",
       "65043_30                      4                      5   \n",
       "65043_36                      5                     15   \n",
       "\n",
       "          updrs_3_plus_12_months  updrs_3_plus_24_months  \\\n",
       "visit_id                                                   \n",
       "55_0                          41                      49   \n",
       "55_6                          38                      49   \n",
       "55_12                         49                      51   \n",
       "55_18                         49                      41   \n",
       "55_24                         51                      52   \n",
       "...                          ...                     ...   \n",
       "65043_12                       0                       5   \n",
       "65043_18                       4                      15   \n",
       "65043_24                       5                      13   \n",
       "65043_30                      15                      11   \n",
       "65043_36                      13                      16   \n",
       "\n",
       "          updrs_4_plus_0_months  updrs_4_plus_6_months  \\\n",
       "visit_id                                                 \n",
       "55_0                          0                      0   \n",
       "55_6                          0                      0   \n",
       "55_12                         0                      0   \n",
       "55_18                         0                      0   \n",
       "55_24                         0                      0   \n",
       "...                         ...                    ...   \n",
       "65043_12                      0                      0   \n",
       "65043_18                      0                      0   \n",
       "65043_24                      0                      0   \n",
       "65043_30                      0                      0   \n",
       "65043_36                      0                      0   \n",
       "\n",
       "          updrs_4_plus_12_months  updrs_4_plus_24_months  \n",
       "visit_id                                                  \n",
       "55_0                           0                       0  \n",
       "55_6                           0                       0  \n",
       "55_12                          0                       0  \n",
       "55_18                          0                       0  \n",
       "55_24                          0                       0  \n",
       "...                          ...                     ...  \n",
       "65043_12                       0                       0  \n",
       "65043_18                       0                       0  \n",
       "65043_24                       0                       0  \n",
       "65043_30                       0                       1  \n",
       "65043_36                       0                       1  \n",
       "\n",
       "[954 rows x 16 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_response = formatted_response\n",
    "train_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "743de822",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-18T20:49:05.394919Z",
     "iopub.status.busy": "2023-05-18T20:49:05.394610Z",
     "iopub.status.idle": "2023-05-18T20:49:05.421160Z",
     "shell.execute_reply": "2023-05-18T20:49:05.419887Z"
    },
    "papermill": {
     "duration": 0.126407,
     "end_time": "2023-05-18T20:49:05.422880",
     "exception": false,
     "start_time": "2023-05-18T20:49:05.296473",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>updrs_2_plus_12_months</th>\n",
       "      <th>updrs_2_plus_24_months</th>\n",
       "      <th>updrs_3_plus_0_months</th>\n",
       "      <th>updrs_3_plus_6_months</th>\n",
       "      <th>updrs_3_plus_12_months</th>\n",
       "      <th>updrs_3_plus_24_months</th>\n",
       "      <th>updrs_4_plus_0_months</th>\n",
       "      <th>updrs_4_plus_6_months</th>\n",
       "      <th>updrs_4_plus_12_months</th>\n",
       "      <th>updrs_4_plus_24_months</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>visit_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>55_0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.000591</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.826263</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16.530260</td>\n",
       "      <td>10.680049</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>15</td>\n",
       "      <td>34</td>\n",
       "      <td>41</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55_6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.513136</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.417006</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>17.678373</td>\n",
       "      <td>11.336211</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>34</td>\n",
       "      <td>41</td>\n",
       "      <td>38</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55_12</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.494810</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.715164</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.299711</td>\n",
       "      <td>10.330498</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>18</td>\n",
       "      <td>41</td>\n",
       "      <td>38</td>\n",
       "      <td>49</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55_18</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.755474</td>\n",
       "      <td>5.442881</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>13</td>\n",
       "      <td>20</td>\n",
       "      <td>38</td>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55_24</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.543486</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.200885</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>18</td>\n",
       "      <td>16</td>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "      <td>51</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65043_12</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.871954</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.297300</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.561789</td>\n",
       "      <td>9.674005</td>\n",
       "      <td>2.305862</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65043_18</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.755474</td>\n",
       "      <td>5.442881</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65043_24</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.641208</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.529390</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.961373</td>\n",
       "      <td>15.328713</td>\n",
       "      <td>1.485610</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65043_30</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.579783</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.165991</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65043_36</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.474138</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>13</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>954 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0    1          2    3          4         5         6          7  \\\n",
       "visit_id                                                                       \n",
       "55_0      0.0  0.0  22.000591  0.0  21.826263  0.000000  0.000000  16.530260   \n",
       "55_6      0.0  0.0  23.513136  0.0  23.417006  0.000000  0.000000  17.678373   \n",
       "55_12     0.0  0.0  16.494810  0.0  14.715164  0.000000  0.000000  10.299711   \n",
       "55_18     0.0  0.0   0.000000  0.0   0.000000  0.000000  0.000000   7.755474   \n",
       "55_24     0.0  0.0   3.543486  0.0   0.000000  5.200885  0.000000   0.000000   \n",
       "...       ...  ...        ...  ...        ...       ...       ...        ...   \n",
       "65043_12  0.0  0.0  15.871954  0.0  21.297300  0.000000  0.000000  11.561789   \n",
       "65043_18  0.0  0.0   0.000000  0.0   0.000000  0.000000  0.000000   7.755474   \n",
       "65043_24  0.0  0.0  14.641208  0.0  12.529390  0.000000  0.000000   6.961373   \n",
       "65043_30  0.0  0.0   0.000000  0.0   0.000000  0.000000  6.579783   0.000000   \n",
       "65043_36  0.0  0.0   0.000000  0.0   0.000000  0.000000  0.000000   1.474138   \n",
       "\n",
       "                  8         9  ...  updrs_2_plus_12_months  \\\n",
       "visit_id                       ...                           \n",
       "55_0      10.680049  0.000000  ...                      10   \n",
       "55_6      11.336211  0.000000  ...                      13   \n",
       "55_12     10.330498  0.000000  ...                       9   \n",
       "55_18      5.442881  0.000000  ...                      13   \n",
       "55_24      0.000000  0.000000  ...                      18   \n",
       "...             ...       ...  ...                     ...   \n",
       "65043_12   9.674005  2.305862  ...                       8   \n",
       "65043_18   5.442881  0.000000  ...                       4   \n",
       "65043_24  15.328713  1.485610  ...                       7   \n",
       "65043_30   0.000000  8.165991  ...                      10   \n",
       "65043_36   0.000000  0.000000  ...                       6   \n",
       "\n",
       "          updrs_2_plus_24_months  updrs_3_plus_0_months  \\\n",
       "visit_id                                                  \n",
       "55_0                           9                     15   \n",
       "55_6                          13                     34   \n",
       "55_12                         18                     41   \n",
       "55_18                         20                     38   \n",
       "55_24                         16                     49   \n",
       "...                          ...                    ...   \n",
       "65043_12                       7                     14   \n",
       "65043_18                      10                     13   \n",
       "65043_24                       6                      0   \n",
       "65043_30                       8                      4   \n",
       "65043_36                       6                      5   \n",
       "\n",
       "          updrs_3_plus_6_months  updrs_3_plus_12_months  \\\n",
       "visit_id                                                  \n",
       "55_0                         34                      41   \n",
       "55_6                         41                      38   \n",
       "55_12                        38                      49   \n",
       "55_18                        49                      49   \n",
       "55_24                        49                      51   \n",
       "...                         ...                     ...   \n",
       "65043_12                     13                       0   \n",
       "65043_18                      0                       4   \n",
       "65043_24                      4                       5   \n",
       "65043_30                      5                      15   \n",
       "65043_36                     15                      13   \n",
       "\n",
       "          updrs_3_plus_24_months  updrs_4_plus_0_months  \\\n",
       "visit_id                                                  \n",
       "55_0                          49                      0   \n",
       "55_6                          49                      0   \n",
       "55_12                         51                      0   \n",
       "55_18                         41                      0   \n",
       "55_24                         52                      0   \n",
       "...                          ...                    ...   \n",
       "65043_12                       5                      0   \n",
       "65043_18                      15                      0   \n",
       "65043_24                      13                      0   \n",
       "65043_30                      11                      0   \n",
       "65043_36                      16                      0   \n",
       "\n",
       "          updrs_4_plus_6_months  updrs_4_plus_12_months  \\\n",
       "visit_id                                                  \n",
       "55_0                          0                       0   \n",
       "55_6                          0                       0   \n",
       "55_12                         0                       0   \n",
       "55_18                         0                       0   \n",
       "55_24                         0                       0   \n",
       "...                         ...                     ...   \n",
       "65043_12                      0                       0   \n",
       "65043_18                      0                       0   \n",
       "65043_24                      0                       0   \n",
       "65043_30                      0                       0   \n",
       "65043_36                      0                       0   \n",
       "\n",
       "          updrs_4_plus_24_months  \n",
       "visit_id                          \n",
       "55_0                           0  \n",
       "55_6                           0  \n",
       "55_12                          0  \n",
       "55_18                          0  \n",
       "55_24                          0  \n",
       "...                          ...  \n",
       "65043_12                       0  \n",
       "65043_18                       0  \n",
       "65043_24                       0  \n",
       "65043_30                       1  \n",
       "65043_36                       1  \n",
       "\n",
       "[954 rows x 27 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Join into one training set\n",
    "train = train_features.merge(\n",
    "    train_response, left_index = True, right_index = True, \n",
    "    how = \"right\")\n",
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "087d66c7",
   "metadata": {
    "papermill": {
     "duration": 0.09601,
     "end_time": "2023-05-18T20:49:05.615160",
     "exception": false,
     "start_time": "2023-05-18T20:49:05.519150",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b2b419f3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-18T20:49:05.807677Z",
     "iopub.status.busy": "2023-05-18T20:49:05.807341Z",
     "iopub.status.idle": "2023-05-18T20:49:05.981723Z",
     "shell.execute_reply": "2023-05-18T20:49:05.980854Z"
    },
    "papermill": {
     "duration": 0.273235,
     "end_time": "2023-05-18T20:49:05.984073",
     "exception": false,
     "start_time": "2023-05-18T20:49:05.710838",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Training Setup\n",
    "import keras_tuner\n",
    "\n",
    "X = train.iloc[:, :latent_shape + 1]\n",
    "y = train.iloc[:, train.shape[1] - 16:].astype('float')\n",
    "\n",
    "input_shape = X.shape[1]\n",
    "output_shape = y.shape[1]\n",
    "#print(X)\n",
    "#print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4f00a2a9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-18T20:49:06.181555Z",
     "iopub.status.busy": "2023-05-18T20:49:06.181025Z",
     "iopub.status.idle": "2023-05-18T20:49:06.186392Z",
     "shell.execute_reply": "2023-05-18T20:49:06.185775Z"
    },
    "papermill": {
     "duration": 0.104604,
     "end_time": "2023-05-18T20:49:06.187970",
     "exception": false,
     "start_time": "2023-05-18T20:49:06.083366",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Setup custom loss function \n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "def smape_loss(y_true, y_pred):\n",
    "    epsilon = 0.1\n",
    "    numer = K.abs(y_pred - y_true)\n",
    "    denom = K.maximum(K.abs(y_true) + K.abs(y_pred) + epsilon, 0.5 + epsilon)\n",
    "    smape = numer / (denom/2)\n",
    "    smape = tf.where(tf.math.is_nan(smape), tf.zeros_like(smape), smape)\n",
    "    return smape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6061760d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-18T20:49:06.386372Z",
     "iopub.status.busy": "2023-05-18T20:49:06.385853Z",
     "iopub.status.idle": "2023-05-18T20:49:06.441582Z",
     "shell.execute_reply": "2023-05-18T20:49:06.440299Z"
    },
    "papermill": {
     "duration": 0.157516,
     "end_time": "2023-05-18T20:49:06.443849",
     "exception": false,
     "start_time": "2023-05-18T20:49:06.286333",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x7b85496db790>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hypermodel Building Function \n",
    "def build_model(hp):\n",
    "    model = keras.Sequential()\n",
    "    # Input Layer\n",
    "    model.add(keras.Input(shape = input_shape))\n",
    "\n",
    "    # Tune the number of hidden layers\n",
    "    for i in range(hp.Int(\"num_layers\", min_value = 1, max_value = 5, step = 1)):\n",
    "        model.add(\n",
    "            # Tune the number of nodes in each layer\n",
    "            layers.Dense(\n",
    "                units = hp.Int(f\"units{i}\", min_value = 10, max_value = 30, step = 10), \n",
    "                # Tune activation function between layers\n",
    "                activation = \"relu\")\n",
    "        )\n",
    "        # Dropout layer after each hidden layer to discourage overfitting\n",
    "        model.add(\n",
    "            layers.Dropout(\n",
    "                rate = hp.Float(\"Dropout\", min_value = 0, max_value = 0.5, step = 0.1)\n",
    "            )\n",
    "        )\n",
    "            \n",
    "    # Output Layer\n",
    "    model.add(layers.Dense(output_shape))\n",
    "\n",
    "    # Learning rate schedule with decay. \n",
    "    learning_rate_fn = keras.optimizers.schedules.PiecewiseConstantDecay(\n",
    "        boundaries = [500], values = [0.01, 0.001])\n",
    "\n",
    "    # Model Compiler\n",
    "    model.compile(\n",
    "        loss = smape_loss, \n",
    "        optimizer = keras.optimizers.Adam(learning_rate = learning_rate_fn)\n",
    "    )\n",
    "\n",
    "    return model \n",
    "\n",
    "build_model(keras_tuner.HyperParameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d7268930",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-18T20:49:06.641493Z",
     "iopub.status.busy": "2023-05-18T20:49:06.641143Z",
     "iopub.status.idle": "2023-05-18T20:49:06.674209Z",
     "shell.execute_reply": "2023-05-18T20:49:06.673339Z"
    },
    "papermill": {
     "duration": 0.134831,
     "end_time": "2023-05-18T20:49:06.676169",
     "exception": false,
     "start_time": "2023-05-18T20:49:06.541338",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search space summary\n",
      "Default search space size: 3\n",
      "num_layers (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 1, 'max_value': 5, 'step': 1, 'sampling': 'linear'}\n",
      "units0 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 10, 'max_value': 30, 'step': 10, 'sampling': 'linear'}\n",
      "Dropout (Float)\n",
      "{'default': 0.0, 'conditions': [], 'min_value': 0.0, 'max_value': 0.5, 'step': 0.1, 'sampling': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "# Hyperband Tunner\n",
    "tuner = keras_tuner.Hyperband(\n",
    "    hypermodel = build_model, \n",
    "    objective = \"val_loss\", \n",
    "    max_epochs = 100, \n",
    "    overwrite = True,\n",
    "    seed = 123\n",
    ")\n",
    "\n",
    "tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "de1c06c1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-18T20:49:06.923934Z",
     "iopub.status.busy": "2023-05-18T20:49:06.922886Z",
     "iopub.status.idle": "2023-05-18T20:49:06.926377Z",
     "shell.execute_reply": "2023-05-18T20:49:06.925859Z"
    },
    "papermill": {
     "duration": 0.102945,
     "end_time": "2023-05-18T20:49:06.928151",
     "exception": false,
     "start_time": "2023-05-18T20:49:06.825206",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Apply Model Tunner\n",
    "#tuner.search(X, y, validation_split = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "084c3a8d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-18T20:49:07.122286Z",
     "iopub.status.busy": "2023-05-18T20:49:07.121260Z",
     "iopub.status.idle": "2023-05-18T20:49:07.206287Z",
     "shell.execute_reply": "2023-05-18T20:49:07.205080Z"
    },
    "papermill": {
     "duration": 0.183967,
     "end_time": "2023-05-18T20:49:07.208008",
     "exception": false,
     "start_time": "2023-05-18T20:49:07.024041",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_11 (Dense)            (None, 20)                240       \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 20)                420       \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 20)                420       \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 10)                210       \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 30)                330       \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 16)                496       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,116\n",
      "Trainable params: 2,116\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Final Model defined based on manuel stop to Hyperband Tuning\n",
    "model_final = tf.keras.Sequential()\n",
    "model_final.add(keras.Input(shape = input_shape))\n",
    "model_final.add(Dense(20, activation = 'relu'))\n",
    "model_final.add(Dense(20, activation = 'relu'))\n",
    "model_final.add(Dense(20, activation = 'relu'))\n",
    "model_final.add(Dense(10, activation = 'relu'))\n",
    "model_final.add(Dense(30, activation = 'relu'))\n",
    "model_final.add(Dense(output_shape))\n",
    "model_final.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2b4218ff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-18T20:49:07.406192Z",
     "iopub.status.busy": "2023-05-18T20:49:07.405834Z",
     "iopub.status.idle": "2023-05-18T20:49:07.417266Z",
     "shell.execute_reply": "2023-05-18T20:49:07.416286Z"
    },
    "papermill": {
     "duration": 0.113898,
     "end_time": "2023-05-18T20:49:07.419404",
     "exception": false,
     "start_time": "2023-05-18T20:49:07.305506",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "learning_rate_fn = keras.optimizers.schedules.PiecewiseConstantDecay(\n",
    "        boundaries = [500], values = [0.01, 0.001])\n",
    "\n",
    "model_final.compile(keras.optimizers.Adam(learning_rate = learning_rate_fn), \n",
    "              loss = smape_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0d334aa2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-18T20:49:07.620786Z",
     "iopub.status.busy": "2023-05-18T20:49:07.620438Z",
     "iopub.status.idle": "2023-05-18T20:49:31.698806Z",
     "shell.execute_reply": "2023-05-18T20:49:31.697659Z"
    },
    "papermill": {
     "duration": 24.180836,
     "end_time": "2023-05-18T20:49:31.700733",
     "exception": false,
     "start_time": "2023-05-18T20:49:07.519897",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "27/27 [==============================] - 1s 7ms/step - loss: 1.2979 - val_loss: 1.0451\n",
      "Epoch 2/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.9786 - val_loss: 0.9486\n",
      "Epoch 3/300\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.9162 - val_loss: 0.8790\n",
      "Epoch 4/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.8875 - val_loss: 0.8745\n",
      "Epoch 5/300\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.8774 - val_loss: 0.8804\n",
      "Epoch 6/300\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.8754 - val_loss: 0.8818\n",
      "Epoch 7/300\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.8708 - val_loss: 0.8651\n",
      "Epoch 8/300\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.8674 - val_loss: 0.8761\n",
      "Epoch 9/300\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.8649 - val_loss: 0.8841\n",
      "Epoch 10/300\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.8665 - val_loss: 0.8582\n",
      "Epoch 11/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.8678 - val_loss: 0.8503\n",
      "Epoch 12/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.8692 - val_loss: 0.8540\n",
      "Epoch 13/300\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.8653 - val_loss: 0.8523\n",
      "Epoch 14/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.8638 - val_loss: 0.8650\n",
      "Epoch 15/300\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.8629 - val_loss: 0.8545\n",
      "Epoch 16/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.8620 - val_loss: 0.8857\n",
      "Epoch 17/300\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.8649 - val_loss: 0.8550\n",
      "Epoch 18/300\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.8612 - val_loss: 0.8605\n",
      "Epoch 19/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.8587 - val_loss: 0.8641\n",
      "Epoch 20/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.8548 - val_loss: 0.8636\n",
      "Epoch 21/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.8538 - val_loss: 0.8638\n",
      "Epoch 22/300\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.8536 - val_loss: 0.8650\n",
      "Epoch 23/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.8530 - val_loss: 0.8631\n",
      "Epoch 24/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.8526 - val_loss: 0.8657\n",
      "Epoch 25/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.8524 - val_loss: 0.8623\n",
      "Epoch 26/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.8522 - val_loss: 0.8627\n",
      "Epoch 27/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.8519 - val_loss: 0.8661\n",
      "Epoch 28/300\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.8515 - val_loss: 0.8637\n",
      "Epoch 29/300\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.8511 - val_loss: 0.8642\n",
      "Epoch 30/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.8514 - val_loss: 0.8617\n",
      "Epoch 31/300\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.8507 - val_loss: 0.8632\n",
      "Epoch 32/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.8505 - val_loss: 0.8628\n",
      "Epoch 33/300\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.8503 - val_loss: 0.8636\n",
      "Epoch 34/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.8499 - val_loss: 0.8624\n",
      "Epoch 35/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.8499 - val_loss: 0.8640\n",
      "Epoch 36/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.8496 - val_loss: 0.8677\n",
      "Epoch 37/300\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.8493 - val_loss: 0.8619\n",
      "Epoch 38/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.8495 - val_loss: 0.8639\n",
      "Epoch 39/300\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.8493 - val_loss: 0.8667\n",
      "Epoch 40/300\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.8492 - val_loss: 0.8675\n",
      "Epoch 41/300\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.8485 - val_loss: 0.8627\n",
      "Epoch 42/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.8479 - val_loss: 0.8653\n",
      "Epoch 43/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.8494 - val_loss: 0.8608\n",
      "Epoch 44/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.8476 - val_loss: 0.8665\n",
      "Epoch 45/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.8478 - val_loss: 0.8617\n",
      "Epoch 46/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.8474 - val_loss: 0.8656\n",
      "Epoch 47/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.8478 - val_loss: 0.8652\n",
      "Epoch 48/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.8473 - val_loss: 0.8658\n",
      "Epoch 49/300\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.8472 - val_loss: 0.8661\n",
      "Epoch 50/300\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.8463 - val_loss: 0.8640\n",
      "Epoch 51/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.8461 - val_loss: 0.8645\n",
      "Epoch 52/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.8457 - val_loss: 0.8643\n",
      "Epoch 53/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.8455 - val_loss: 0.8669\n",
      "Epoch 54/300\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.8458 - val_loss: 0.8664\n",
      "Epoch 55/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.8448 - val_loss: 0.8665\n",
      "Epoch 56/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.8441 - val_loss: 0.8658\n",
      "Epoch 57/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.8449 - val_loss: 0.8636\n",
      "Epoch 58/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.8436 - val_loss: 0.8623\n",
      "Epoch 59/300\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.8409 - val_loss: 0.8597\n",
      "Epoch 60/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.8395 - val_loss: 0.8610\n",
      "Epoch 61/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.8368 - val_loss: 0.8545\n",
      "Epoch 62/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.8248 - val_loss: 0.8303\n",
      "Epoch 63/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.7650 - val_loss: 0.7613\n",
      "Epoch 64/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.7181 - val_loss: 0.7393\n",
      "Epoch 65/300\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.7070 - val_loss: 0.7330\n",
      "Epoch 66/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.6991 - val_loss: 0.7340\n",
      "Epoch 67/300\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.6947 - val_loss: 0.7219\n",
      "Epoch 68/300\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.6949 - val_loss: 0.7284\n",
      "Epoch 69/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.6915 - val_loss: 0.7256\n",
      "Epoch 70/300\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.6892 - val_loss: 0.7229\n",
      "Epoch 71/300\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.6911 - val_loss: 0.7209\n",
      "Epoch 72/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.6890 - val_loss: 0.7223\n",
      "Epoch 73/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.6876 - val_loss: 0.7191\n",
      "Epoch 74/300\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.6876 - val_loss: 0.7215\n",
      "Epoch 75/300\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.6867 - val_loss: 0.7224\n",
      "Epoch 76/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.6876 - val_loss: 0.7214\n",
      "Epoch 77/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.6879 - val_loss: 0.7228\n",
      "Epoch 78/300\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.6865 - val_loss: 0.7197\n",
      "Epoch 79/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.6873 - val_loss: 0.7265\n",
      "Epoch 80/300\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.6865 - val_loss: 0.7244\n",
      "Epoch 81/300\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.6850 - val_loss: 0.7207\n",
      "Epoch 82/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.6851 - val_loss: 0.7221\n",
      "Epoch 83/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.6845 - val_loss: 0.7267\n",
      "Epoch 84/300\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.6851 - val_loss: 0.7218\n",
      "Epoch 85/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.6847 - val_loss: 0.7191\n",
      "Epoch 86/300\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.6832 - val_loss: 0.7192\n",
      "Epoch 87/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.6827 - val_loss: 0.7208\n",
      "Epoch 88/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.6832 - val_loss: 0.7215\n",
      "Epoch 89/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.6822 - val_loss: 0.7218\n",
      "Epoch 90/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.6822 - val_loss: 0.7227\n",
      "Epoch 91/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.6834 - val_loss: 0.7246\n",
      "Epoch 92/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.6813 - val_loss: 0.7204\n",
      "Epoch 93/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.6822 - val_loss: 0.7204\n",
      "Epoch 94/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.6839 - val_loss: 0.7215\n",
      "Epoch 95/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.6819 - val_loss: 0.7229\n",
      "Epoch 96/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.6798 - val_loss: 0.7202\n",
      "Epoch 97/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.6789 - val_loss: 0.7179\n",
      "Epoch 98/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.6784 - val_loss: 0.7202\n",
      "Epoch 99/300\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.6790 - val_loss: 0.7216\n",
      "Epoch 100/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.6777 - val_loss: 0.7174\n",
      "Epoch 101/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.6756 - val_loss: 0.7145\n",
      "Epoch 102/300\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.6753 - val_loss: 0.7166\n",
      "Epoch 103/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.6737 - val_loss: 0.7181\n",
      "Epoch 104/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.6755 - val_loss: 0.7147\n",
      "Epoch 105/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.6779 - val_loss: 0.7147\n",
      "Epoch 106/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.6745 - val_loss: 0.7142\n",
      "Epoch 107/300\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.6749 - val_loss: 0.7104\n",
      "Epoch 108/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.6727 - val_loss: 0.7118\n",
      "Epoch 109/300\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.6704 - val_loss: 0.7086\n",
      "Epoch 110/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.6705 - val_loss: 0.7069\n",
      "Epoch 111/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.6697 - val_loss: 0.7041\n",
      "Epoch 112/300\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.6681 - val_loss: 0.7042\n",
      "Epoch 113/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.6662 - val_loss: 0.7084\n",
      "Epoch 114/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.6651 - val_loss: 0.7071\n",
      "Epoch 115/300\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.6643 - val_loss: 0.7054\n",
      "Epoch 116/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.6622 - val_loss: 0.6997\n",
      "Epoch 117/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.6570 - val_loss: 0.6931\n",
      "Epoch 118/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.6417 - val_loss: 0.6796\n",
      "Epoch 119/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.6290 - val_loss: 0.6696\n",
      "Epoch 120/300\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.6269 - val_loss: 0.6696\n",
      "Epoch 121/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.6263 - val_loss: 0.6704\n",
      "Epoch 122/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.6247 - val_loss: 0.6635\n",
      "Epoch 123/300\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.6232 - val_loss: 0.6612\n",
      "Epoch 124/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.6169 - val_loss: 0.6605\n",
      "Epoch 125/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.6180 - val_loss: 0.6626\n",
      "Epoch 126/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.6168 - val_loss: 0.6632\n",
      "Epoch 127/300\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.6168 - val_loss: 0.6682\n",
      "Epoch 128/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.6592\n",
      "Epoch 129/300\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.6137 - val_loss: 0.6610\n",
      "Epoch 130/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.6134 - val_loss: 0.6619\n",
      "Epoch 131/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.6137 - val_loss: 0.6635\n",
      "Epoch 132/300\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.6138 - val_loss: 0.6630\n",
      "Epoch 133/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.6140 - val_loss: 0.6628\n",
      "Epoch 134/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.6139 - val_loss: 0.6628\n",
      "Epoch 135/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.6129 - val_loss: 0.6654\n",
      "Epoch 136/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.6117 - val_loss: 0.6596\n",
      "Epoch 137/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.6123 - val_loss: 0.6628\n",
      "Epoch 138/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.6124 - val_loss: 0.6649\n",
      "Epoch 139/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.6131 - val_loss: 0.6631\n",
      "Epoch 140/300\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.6128 - val_loss: 0.6604\n",
      "Epoch 141/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.6115 - val_loss: 0.6611\n",
      "Epoch 142/300\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.6108 - val_loss: 0.6570\n",
      "Epoch 143/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.6105 - val_loss: 0.6642\n",
      "Epoch 144/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.6107 - val_loss: 0.6618\n",
      "Epoch 145/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.6100 - val_loss: 0.6620\n",
      "Epoch 146/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.6099 - val_loss: 0.6664\n",
      "Epoch 147/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.6110 - val_loss: 0.6598\n",
      "Epoch 148/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.6097 - val_loss: 0.6629\n",
      "Epoch 149/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.6091 - val_loss: 0.6652\n",
      "Epoch 150/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.6103 - val_loss: 0.6644\n",
      "Epoch 151/300\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.6102 - val_loss: 0.6648\n",
      "Epoch 152/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.6086 - val_loss: 0.6624\n",
      "Epoch 153/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.6077 - val_loss: 0.6654\n",
      "Epoch 154/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.6092 - val_loss: 0.6668\n",
      "Epoch 155/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.6082 - val_loss: 0.6622\n",
      "Epoch 156/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.6066 - val_loss: 0.6631\n",
      "Epoch 157/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.6074 - val_loss: 0.6637\n",
      "Epoch 158/300\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.6077 - val_loss: 0.6634\n",
      "Epoch 159/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.6088 - val_loss: 0.6641\n",
      "Epoch 160/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.6070 - val_loss: 0.6628\n",
      "Epoch 161/300\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.6080 - val_loss: 0.6634\n",
      "Epoch 162/300\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.6076 - val_loss: 0.6613\n",
      "Epoch 163/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.6062 - val_loss: 0.6596\n",
      "Epoch 164/300\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.6058 - val_loss: 0.6580\n",
      "Epoch 165/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.6057 - val_loss: 0.6625\n",
      "Epoch 166/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.6058 - val_loss: 0.6615\n",
      "Epoch 167/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.6057 - val_loss: 0.6623\n",
      "Epoch 168/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.6059 - val_loss: 0.6612\n",
      "Epoch 169/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.6065 - val_loss: 0.6605\n",
      "Epoch 170/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.6056 - val_loss: 0.6595\n",
      "Epoch 171/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.6048 - val_loss: 0.6596\n",
      "Epoch 172/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.6048 - val_loss: 0.6595\n",
      "Epoch 173/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.6047 - val_loss: 0.6591\n",
      "Epoch 174/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.6054 - val_loss: 0.6617\n",
      "Epoch 175/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.6061 - val_loss: 0.6625\n",
      "Epoch 176/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.6040 - val_loss: 0.6577\n",
      "Epoch 177/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.6041 - val_loss: 0.6589\n",
      "Epoch 178/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.6041 - val_loss: 0.6612\n",
      "Epoch 179/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.6038 - val_loss: 0.6589\n",
      "Epoch 180/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.6029 - val_loss: 0.6561\n",
      "Epoch 181/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.6038 - val_loss: 0.6579\n",
      "Epoch 182/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.6037 - val_loss: 0.6589\n",
      "Epoch 183/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.6023 - val_loss: 0.6609\n",
      "Epoch 184/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.6036 - val_loss: 0.6623\n",
      "Epoch 185/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.6014 - val_loss: 0.6608\n",
      "Epoch 186/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.6027 - val_loss: 0.6581\n",
      "Epoch 187/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.6032 - val_loss: 0.6585\n",
      "Epoch 188/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.6021 - val_loss: 0.6655\n",
      "Epoch 189/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.6043 - val_loss: 0.6612\n",
      "Epoch 190/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.6017 - val_loss: 0.6583\n",
      "Epoch 191/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.6017 - val_loss: 0.6623\n",
      "Epoch 192/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.6013 - val_loss: 0.6589\n",
      "Epoch 193/300\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.5999 - val_loss: 0.6673\n",
      "Epoch 194/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.6008 - val_loss: 0.6596\n",
      "Epoch 195/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.5992 - val_loss: 0.6594\n",
      "Epoch 196/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.5995 - val_loss: 0.6608\n",
      "Epoch 197/300\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5997 - val_loss: 0.6645\n",
      "Epoch 198/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.6005 - val_loss: 0.6607\n",
      "Epoch 199/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.5985 - val_loss: 0.6592\n",
      "Epoch 200/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.5995 - val_loss: 0.6652\n",
      "Epoch 201/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.5986 - val_loss: 0.6647\n",
      "Epoch 202/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.5968 - val_loss: 0.6667\n",
      "Epoch 203/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.6003 - val_loss: 0.6628\n",
      "Epoch 204/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.5990 - val_loss: 0.6626\n",
      "Epoch 205/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.5971 - val_loss: 0.6639\n",
      "Epoch 206/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.5973 - val_loss: 0.6664\n",
      "Epoch 207/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.5959 - val_loss: 0.6589\n",
      "Epoch 208/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.5967 - val_loss: 0.6600\n",
      "Epoch 209/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.5954 - val_loss: 0.6605\n",
      "Epoch 210/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.5948 - val_loss: 0.6615\n",
      "Epoch 211/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.5947 - val_loss: 0.6597\n",
      "Epoch 212/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.5934 - val_loss: 0.6590\n",
      "Epoch 213/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.5941 - val_loss: 0.6612\n",
      "Epoch 214/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.5925 - val_loss: 0.6607\n",
      "Epoch 215/300\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5914 - val_loss: 0.6603\n",
      "Epoch 216/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.5925 - val_loss: 0.6541\n",
      "Epoch 217/300\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5922 - val_loss: 0.6587\n",
      "Epoch 218/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.5911 - val_loss: 0.6560\n",
      "Epoch 219/300\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5893 - val_loss: 0.6545\n",
      "Epoch 220/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.5896 - val_loss: 0.6577\n",
      "Epoch 221/300\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5892 - val_loss: 0.6524\n",
      "Epoch 222/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.5879 - val_loss: 0.6505\n",
      "Epoch 223/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.5871 - val_loss: 0.6548\n",
      "Epoch 224/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.5904 - val_loss: 0.6502\n",
      "Epoch 225/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.5867 - val_loss: 0.6532\n",
      "Epoch 226/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.5874 - val_loss: 0.6516\n",
      "Epoch 227/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.5862 - val_loss: 0.6517\n",
      "Epoch 228/300\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5850 - val_loss: 0.6539\n",
      "Epoch 229/300\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5855 - val_loss: 0.6519\n",
      "Epoch 230/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.5856 - val_loss: 0.6496\n",
      "Epoch 231/300\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5833 - val_loss: 0.6508\n",
      "Epoch 232/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.5841 - val_loss: 0.6538\n",
      "Epoch 233/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.5838 - val_loss: 0.6487\n",
      "Epoch 234/300\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.5835 - val_loss: 0.6524\n",
      "Epoch 235/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.5838 - val_loss: 0.6532\n",
      "Epoch 236/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.5827 - val_loss: 0.6493\n",
      "Epoch 237/300\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5831 - val_loss: 0.6502\n",
      "Epoch 238/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.5827 - val_loss: 0.6497\n",
      "Epoch 239/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.5828 - val_loss: 0.6515\n",
      "Epoch 240/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.5815 - val_loss: 0.6474\n",
      "Epoch 241/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.5818 - val_loss: 0.6472\n",
      "Epoch 242/300\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5812 - val_loss: 0.6472\n",
      "Epoch 243/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.5799 - val_loss: 0.6479\n",
      "Epoch 244/300\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5805 - val_loss: 0.6502\n",
      "Epoch 245/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.5808 - val_loss: 0.6473\n",
      "Epoch 246/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.5802 - val_loss: 0.6469\n",
      "Epoch 247/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.5798 - val_loss: 0.6465\n",
      "Epoch 248/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.5820 - val_loss: 0.6491\n",
      "Epoch 249/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.5820 - val_loss: 0.6495\n",
      "Epoch 250/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.5821 - val_loss: 0.6467\n",
      "Epoch 251/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.5790 - val_loss: 0.6490\n",
      "Epoch 252/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.5794 - val_loss: 0.6522\n",
      "Epoch 253/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.5796 - val_loss: 0.6492\n",
      "Epoch 254/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.5791 - val_loss: 0.6499\n",
      "Epoch 255/300\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5783 - val_loss: 0.6487\n",
      "Epoch 256/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.5787 - val_loss: 0.6480\n",
      "Epoch 257/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.5810 - val_loss: 0.6507\n",
      "Epoch 258/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.5792 - val_loss: 0.6508\n",
      "Epoch 259/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.5795 - val_loss: 0.6483\n",
      "Epoch 260/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.5789 - val_loss: 0.6494\n",
      "Epoch 261/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.5792 - val_loss: 0.6489\n",
      "Epoch 262/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.5791 - val_loss: 0.6447\n",
      "Epoch 263/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.5800 - val_loss: 0.6508\n",
      "Epoch 264/300\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5801 - val_loss: 0.6458\n",
      "Epoch 265/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.5788 - val_loss: 0.6511\n",
      "Epoch 266/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.5782 - val_loss: 0.6500\n",
      "Epoch 267/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.5776 - val_loss: 0.6473\n",
      "Epoch 268/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.5771 - val_loss: 0.6484\n",
      "Epoch 269/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.5768 - val_loss: 0.6502\n",
      "Epoch 270/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.5781 - val_loss: 0.6453\n",
      "Epoch 271/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.5777 - val_loss: 0.6495\n",
      "Epoch 272/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.5762 - val_loss: 0.6508\n",
      "Epoch 273/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.5756 - val_loss: 0.6491\n",
      "Epoch 274/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.5774 - val_loss: 0.6478\n",
      "Epoch 275/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.5776 - val_loss: 0.6473\n",
      "Epoch 276/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.5780 - val_loss: 0.6499\n",
      "Epoch 277/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.5791 - val_loss: 0.6512\n",
      "Epoch 278/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.5784 - val_loss: 0.6513\n",
      "Epoch 279/300\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5766 - val_loss: 0.6489\n",
      "Epoch 280/300\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5766 - val_loss: 0.6513\n",
      "Epoch 281/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.5774 - val_loss: 0.6527\n",
      "Epoch 282/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.5760 - val_loss: 0.6491\n",
      "Epoch 283/300\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5757 - val_loss: 0.6500\n",
      "Epoch 284/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.5750 - val_loss: 0.6494\n",
      "Epoch 285/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.5757 - val_loss: 0.6496\n",
      "Epoch 286/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.5764 - val_loss: 0.6496\n",
      "Epoch 287/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.5782 - val_loss: 0.6515\n",
      "Epoch 288/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.5764 - val_loss: 0.6496\n",
      "Epoch 289/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.5743 - val_loss: 0.6521\n",
      "Epoch 290/300\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5751 - val_loss: 0.6495\n",
      "Epoch 291/300\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5764 - val_loss: 0.6497\n",
      "Epoch 292/300\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5762 - val_loss: 0.6525\n",
      "Epoch 293/300\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5764 - val_loss: 0.6516\n",
      "Epoch 294/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.5746 - val_loss: 0.6500\n",
      "Epoch 295/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.5739 - val_loss: 0.6493\n",
      "Epoch 296/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.5748 - val_loss: 0.6525\n",
      "Epoch 297/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.5757 - val_loss: 0.6535\n",
      "Epoch 298/300\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5756 - val_loss: 0.6509\n",
      "Epoch 299/300\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5745 - val_loss: 0.6499\n",
      "Epoch 300/300\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.5742 - val_loss: 0.6525\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot: >"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras.utils.vis_utils import plot_model\n",
    "history = model_final.fit(\n",
    "    X,\n",
    "    y,\n",
    "    epochs = 300,\n",
    "    validation_split = 0.1\n",
    ")\n",
    "\n",
    "pd.DataFrame(history.history).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94671844",
   "metadata": {
    "papermill": {
     "duration": 0.147807,
     "end_time": "2023-05-18T20:49:31.998317",
     "exception": false,
     "start_time": "2023-05-18T20:49:31.850510",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "be6a3eb9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-18T20:49:32.295948Z",
     "iopub.status.busy": "2023-05-18T20:49:32.295639Z",
     "iopub.status.idle": "2023-05-18T20:49:32.303027Z",
     "shell.execute_reply": "2023-05-18T20:49:32.302311Z"
    },
    "papermill": {
     "duration": 0.159038,
     "end_time": "2023-05-18T20:49:32.304524",
     "exception": false,
     "start_time": "2023-05-18T20:49:32.145486",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def prepare_features(clinical, protein, peptides):\n",
    "    \n",
    "    # Match input format.\n",
    "    clinical = clinical[['patient_id', 'visit_month', 'visit_id']]\n",
    "    protein = protein.drop('group_key', axis = 1, errors = 'ignore')\n",
    "    peptides = peptides.drop('group_key', axis = 1, errors = 'ignore')\n",
    "    \n",
    "    # Apply recipe. \n",
    "    clean = recipe(clinical, protein, peptides, rep = False)\n",
    "    \n",
    "    # Drop duplicate rows.\n",
    "    clean = clean[~clean.index.duplicated(keep='first')]\n",
    "    \n",
    "    # Add features not seen during testing as 0.\n",
    "    test_add = np.setdiff1d(clean_test.columns, \n",
    "                            clean.columns).tolist()\n",
    "        \n",
    "    temp = pd.DataFrame(0, \n",
    "                        columns = test_add, \n",
    "                        index = clean.index)\n",
    "    clean = clean.join(temp)\n",
    "    \n",
    "    # Drop any features not seen during training.\n",
    "    train_drops = np.setdiff1d(clean.columns, \n",
    "                               clean_test.columns).tolist()\n",
    "    clean = clean.drop(train_drops, axis = 1)\n",
    "    \n",
    "    # Apply encoder\n",
    "    clean_pep_pro = clean.iloc[:, :clean.shape[1] - 5]\n",
    "    clean_pep_pro = encoder.predict(clean_pep_pro)\n",
    "    clean_encoded = pd.DataFrame(clean_pep_pro)\n",
    "    clean_encoded = clean_encoded.set_index(clean.index)\n",
    "    \n",
    "    clean = clean_encoded.join(clean['visit_month'])\n",
    "\n",
    "    return clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6e76d77e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-18T20:49:32.606052Z",
     "iopub.status.busy": "2023-05-18T20:49:32.605465Z",
     "iopub.status.idle": "2023-05-18T20:49:32.608618Z",
     "shell.execute_reply": "2023-05-18T20:49:32.608064Z"
    },
    "papermill": {
     "duration": 0.155565,
     "end_time": "2023-05-18T20:49:32.610225",
     "exception": false,
     "start_time": "2023-05-18T20:49:32.454660",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Test prepare function \n",
    "#test_prep = prepare_features(train_clinical, train_protein, train_peptide)\n",
    "#test_prep.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c5f0e6f3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-18T20:49:32.906295Z",
     "iopub.status.busy": "2023-05-18T20:49:32.905747Z",
     "iopub.status.idle": "2023-05-18T20:49:32.910881Z",
     "shell.execute_reply": "2023-05-18T20:49:32.909524Z"
    },
    "papermill": {
     "duration": 0.1545,
     "end_time": "2023-05-18T20:49:32.913131",
     "exception": false,
     "start_time": "2023-05-18T20:49:32.758631",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_predictions(features, model):\n",
    "    pred_submission = np.around(np.abs(model.predict(features)),0)\n",
    "    pred_submission = pd.DataFrame(pred_submission, index = features.index, columns = y.columns)\n",
    "    return pred_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7f64f160",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-18T20:49:33.215250Z",
     "iopub.status.busy": "2023-05-18T20:49:33.214924Z",
     "iopub.status.idle": "2023-05-18T20:49:33.219641Z",
     "shell.execute_reply": "2023-05-18T20:49:33.218697Z"
    },
    "papermill": {
     "duration": 0.157803,
     "end_time": "2023-05-18T20:49:33.221599",
     "exception": false,
     "start_time": "2023-05-18T20:49:33.063796",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Prediction Test\n",
    "#test_pred = get_predictions(test_prep, model_final)\n",
    "#print(formatted_response)\n",
    "#print(test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "24d625eb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-18T20:49:33.575312Z",
     "iopub.status.busy": "2023-05-18T20:49:33.574999Z",
     "iopub.status.idle": "2023-05-18T20:49:33.580943Z",
     "shell.execute_reply": "2023-05-18T20:49:33.579805Z"
    },
    "papermill": {
     "duration": 0.210027,
     "end_time": "2023-05-18T20:49:33.582707",
     "exception": false,
     "start_time": "2023-05-18T20:49:33.372680",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def format_predictions(predictions, sample_submission):\n",
    "    \"\"\"Format predictions for submission\"\"\"\n",
    "    pred_submission = pd.DataFrame(predictions.stack())\n",
    "\n",
    "    # Map predictions to sample_submission\n",
    "    pred_submission.index = pred_submission.index.map('_'.join)\n",
    "    pred_submission.columns = ['rating']\n",
    "    sample_submission.rating = sample_submission.prediction_id.map(pred_submission.rating)\n",
    "    \n",
    "    return sample_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0bb4c693",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-18T20:49:33.881708Z",
     "iopub.status.busy": "2023-05-18T20:49:33.880656Z",
     "iopub.status.idle": "2023-05-18T20:49:33.885475Z",
     "shell.execute_reply": "2023-05-18T20:49:33.884243Z"
    },
    "papermill": {
     "duration": 0.156012,
     "end_time": "2023-05-18T20:49:33.887322",
     "exception": false,
     "start_time": "2023-05-18T20:49:33.731310",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/kaggle/input/amp-parkinsons-disease-progression-prediction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9dccbaab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-18T20:49:34.184145Z",
     "iopub.status.busy": "2023-05-18T20:49:34.183812Z",
     "iopub.status.idle": "2023-05-18T20:49:34.217654Z",
     "shell.execute_reply": "2023-05-18T20:49:34.216994Z"
    },
    "papermill": {
     "duration": 0.186313,
     "end_time": "2023-05-18T20:49:34.219751",
     "exception": false,
     "start_time": "2023-05-18T20:49:34.033438",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import amp_pd_peptide_310\n",
    "env = amp_pd_peptide_310.make_env()   # initialize the environment\n",
    "amp_pd_peptide_310.make_env.func_dict['__called__'] = False\n",
    "iter_test = env.iter_test()    # an iterator which loops over the test files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cd36be94",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-18T20:49:34.523452Z",
     "iopub.status.busy": "2023-05-18T20:49:34.522189Z",
     "iopub.status.idle": "2023-05-18T20:49:35.580852Z",
     "shell.execute_reply": "2023-05-18T20:49:35.579805Z"
    },
    "papermill": {
     "duration": 1.211724,
     "end_time": "2023-05-18T20:49:35.583108",
     "exception": false,
     "start_time": "2023-05-18T20:49:34.371384",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This version of the API is not optimized and should not be used to estimate the runtime of your code on the hidden test set.\n",
      "Preprocessing Steps\n",
      "1. Add Peptide/Protein as new feature.\n",
      "3. Dropped patient_id as a predictor.\n",
      "4. Normalized numeric predictors.\n",
      "5. KNN Imputation\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "Preprocessing Steps\n",
      "1. Add Peptide/Protein as new feature.\n",
      "3. Dropped patient_id as a predictor.\n",
      "4. Normalized numeric predictors.\n",
      "5. KNN Imputation\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n"
     ]
    }
   ],
   "source": [
    "for (test, test_peptides, test_proteins, sample_submission) in iter_test:\n",
    "    sub_features = prepare_features(test, test_proteins, test_peptides)\n",
    "    sub_predictions = get_predictions(sub_features, model_final)\n",
    "    submission = format_predictions(sub_predictions, sample_submission)\n",
    "\n",
    "    env.predict(submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "12b3c1ea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-18T20:49:35.885190Z",
     "iopub.status.busy": "2023-05-18T20:49:35.884862Z",
     "iopub.status.idle": "2023-05-18T20:49:35.898028Z",
     "shell.execute_reply": "2023-05-18T20:49:35.896693Z"
    },
    "papermill": {
     "duration": 0.165353,
     "end_time": "2023-05-18T20:49:35.900037",
     "exception": false,
     "start_time": "2023-05-18T20:49:35.734684",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prediction_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3342_0_updrs_1_plus_0_months</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3342_0_updrs_1_plus_6_months</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3342_0_updrs_1_plus_12_months</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3342_0_updrs_1_plus_24_months</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3342_0_updrs_2_plus_0_months</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>50423_6_updrs_3_plus_24_months</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>50423_6_updrs_4_plus_0_months</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>50423_6_updrs_4_plus_6_months</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>50423_6_updrs_4_plus_12_months</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>50423_6_updrs_4_plus_24_months</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     prediction_id  rating\n",
       "0     3342_0_updrs_1_plus_0_months     9.0\n",
       "1     3342_0_updrs_1_plus_6_months     8.0\n",
       "2    3342_0_updrs_1_plus_12_months     9.0\n",
       "3    3342_0_updrs_1_plus_24_months    10.0\n",
       "4     3342_0_updrs_2_plus_0_months     8.0\n",
       "..                             ...     ...\n",
       "59  50423_6_updrs_3_plus_24_months    23.0\n",
       "60   50423_6_updrs_4_plus_0_months     0.0\n",
       "61   50423_6_updrs_4_plus_6_months     0.0\n",
       "62  50423_6_updrs_4_plus_12_months     0.0\n",
       "63  50423_6_updrs_4_plus_24_months     4.0\n",
       "\n",
       "[64 rows x 2 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('/kaggle/working/submission.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 177.50217,
   "end_time": "2023-05-18T20:49:39.405695",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-05-18T20:46:41.903525",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
